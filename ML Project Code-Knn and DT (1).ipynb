{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84ee79-aa69-4c1f-9a52-e36dedbd1d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopy\n",
    "!pip install folium\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87430fb9-ba31-45bf-babf-f78ac0d60060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import os\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.chdir('/Users/clarazhou/Documents/UTdallas 24Fall/6341 ML/archive (5)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647bcdb-9f86-4d4c-b2de-a9618acbc7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c9d19a-9481-4ec4-95f4-efaed35701d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning:\n",
    "\n",
    "# 1.Remove '(min)' from 'Time_taken(min)' and convert it to an integer\n",
    "data['Time_taken(min)'] = data['Time_taken(min)'].str.replace(r'\\(min\\)\\s*', '', regex=True).astype(int)\n",
    "# 2. Remove the 'conditions' prefix from 'Weather conditions'\n",
    "data['Weatherconditions'] = data['Weatherconditions'].str.replace('conditions ', '')\n",
    "\n",
    "# 3. Convert to numeric\n",
    "data['Delivery_person_Age'] = pd.to_numeric(data['Delivery_person_Age'], errors='coerce')  # convert to int, NaNs if invalid\n",
    "data['Delivery_person_Ratings'] = pd.to_numeric(data['Delivery_person_Ratings'], errors='coerce')  # convert to float\n",
    "data['multiple_deliveries'] = pd.to_numeric(data['multiple_deliveries'], errors='coerce')  # convert to int (handle NaNs)\n",
    "\n",
    "# 4. Convert to categorical\n",
    "categorical_columns = [\n",
    "    'Weatherconditions',\n",
    "    'Road_traffic_density',\n",
    "    'Type_of_order',\n",
    "    'Type_of_vehicle',\n",
    "    'Festival',\n",
    "    'City'\n",
    "]\n",
    "data[categorical_columns] = data[categorical_columns].astype('category')\n",
    "\n",
    "# 5. Convert negative latitudes and longitudes to positive for both restaurant and delivery locations\n",
    "data['Restaurant_latitude'] = data['Restaurant_latitude'].abs()\n",
    "data['Restaurant_longitude'] = data['Restaurant_longitude'].abs()\n",
    "data['Delivery_location_latitude'] = data['Delivery_location_latitude'].abs()\n",
    "data['Delivery_location_longitude'] = data['Delivery_location_longitude'].abs()\n",
    "\n",
    "#6. Convert to datetime\n",
    "data['Time_Orderd'] = pd.to_datetime(data['Time_Orderd'], errors='coerce')\n",
    "data['Time_Order_picked'] = pd.to_datetime(data['Time_Order_picked'], errors='coerce')\n",
    "\n",
    "#7. Check for missing values (NaN) in each column of the dataset\n",
    "missing_value = data.isna().sum() + ((data == 'NaN') | (data == 'NaN ')).sum()\n",
    "# Display the number of missing values for each column\n",
    "print(missing_value)\n",
    "# remove the number of blank (missing) values is exactly 3 among the total 12 columns\n",
    "cols_to_check = [\n",
    "    'Delivery_person_Age',\n",
    "    'Delivery_person_Ratings',\n",
    "    'Time_Orderd',\n",
    "    'Weatherconditions',\n",
    "    'Road_traffic_density',\n",
    "    'multiple_deliveries',\n",
    "    'Festival',\n",
    "    'City'\n",
    "]\n",
    "\n",
    "def is_blank(val):\n",
    "    return pd.isna(val) or str(val).strip().lower() == 'nan'\n",
    "rows_with_3_blank = data[cols_to_check].applymap(is_blank).sum(axis=1) == 3\n",
    "data = data[~rows_with_3_blank]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304750d-b142-4878-a369-8c686a34fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Function to calculate distance between restaurant and delivery location (in km)\n",
    "def calculate_distance(row):\n",
    "    restaurant_coords = (row['Restaurant_latitude'], row['Restaurant_longitude'])\n",
    "    delivery_coords = (row['Delivery_location_latitude'], row['Delivery_location_longitude'])\n",
    "    return geodesic(restaurant_coords, delivery_coords).km  # return distance in km\n",
    "data['Delivery_distance_km'] = data.apply(calculate_distance, axis=1)\n",
    "#9. add new column 'Order_to_Pickup_Duration'\n",
    "duration = data['Time_Order_picked'] - data['Time_Orderd']\n",
    "duration = duration.where(duration >= pd.Timedelta(0), duration + pd.Timedelta(days=1))\n",
    "\n",
    "data['Order_to_Pickup_Duration'] = duration.dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c841ffb1-f18b-428d-a16e-188bb4d4a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract restaurant latitude and longitude columns\n",
    "restaurant_data = data[['Restaurant_latitude', 'Restaurant_longitude']]\n",
    "\n",
    "# Step 2: Create map centered on India\n",
    "india_center = [20.5937, 78.9629]\n",
    "map_all_restaurants = folium.Map(location=india_center, zoom_start=5)\n",
    "\n",
    "# Step 3: Plot all restaurant latitudes and longitudes\n",
    "for _, row in restaurant_data.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['Restaurant_latitude'], row['Restaurant_longitude']],\n",
    "        radius=3,\n",
    "        color='blue',  # Blue color for restaurant locations\n",
    "        fill=True,\n",
    "        fill_opacity=0.6\n",
    "    ).add_to(map_all_restaurants)\n",
    "\n",
    "# Step 4: Save the map as an HTML file to view\n",
    "map_all_restaurants\n",
    "#map_all_restaurants.save(\"all_restaurants_map.html\")\n",
    "#print(\"✅ Map saved as 'all_restaurants_map.html'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b635b-d997-46fc-b49a-0b3806fa96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Extract delivery location latitude and longitude columns\n",
    "delivery_data = data[['Delivery_location_latitude', 'Delivery_location_longitude']]    \n",
    "\n",
    "# Step 2: Create map centered on India\n",
    "india_center = [20.5937, 78.9629]\n",
    "map_all_delivery_locations = folium.Map(location=india_center, zoom_start=5)\n",
    "\n",
    "# Step 3: Plot all restaurant latitudes and longitudes\n",
    "for _, row in delivery_data.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['Delivery_location_latitude'], row['Delivery_location_longitude']],\n",
    "        radius=3,\n",
    "        color='red',  # red color for delivery locations\n",
    "        fill=True,\n",
    "        fill_opacity=0.6\n",
    "    ).add_to(map_all_delivery_locations)\n",
    "\n",
    "# Step 4: Save the map as an HTML file to view\n",
    "map_all_delivery_locations\n",
    "#map_all_delivery_locations.save(\"map_all_delivery_locations.html\")\n",
    "#print(\"✅ Map saved as 'map_all_delivery_locations.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260679ed-708e-433d-81f5-af532800b391",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_vars = ['Delivery_person_Age', 'Delivery_person_Ratings', \n",
    "                  'Delivery_distance_km', 'multiple_deliveries','Order_to_Pickup_Duration']\n",
    "\n",
    "categorical_vars = ['Vehicle_condition', 'Weatherconditions', 'Type_of_order',\n",
    "                    'Type_of_vehicle', 'Festival', 'City', 'Road_traffic_density']\n",
    "\n",
    "y = data['Time_taken(min)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12140f2c-5d5b-4bd3-b482-fd3cfdba4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "all_vars = numerical_vars + categorical_vars\n",
    "for i, var in enumerate(all_vars):\n",
    "    plt.subplot(4, 3, i+1)\n",
    "    sns.histplot(data[var].dropna(), kde=False, bins=30, color='skyblue')\n",
    "    plt.title(f'Distribution of {var}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829bb2f5-25d6-4495-bd15-3507b700573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#according to the above figure, choose 'Delivery_person_Ratings', 'Festival', and 'City' \n",
    "#missing values with the mode (most frequent value)\n",
    "\n",
    "mode_rating = data['Delivery_person_Ratings'].mode()[0]\n",
    "data['Delivery_person_Ratings'].fillna(mode_rating, inplace=True)\n",
    "\n",
    "data['Festival'] = (\n",
    "    data['Festival'].astype(str).str.strip().replace('NaN', np.nan)\n",
    ")\n",
    "data['Festival'].fillna(data['Festival'].mode()[0], inplace=True)\n",
    "\n",
    "data['City'] = (\n",
    "    data['City'].astype(str).str.strip().replace('NaN', np.nan)\n",
    ")\n",
    "data['City'].fillna(data['City'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff042010-966e-439f-8164-7d27d4a67d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the original records， and remove these missing value records. only 4%\n",
    "\n",
    "original_rows = data.shape[0]\n",
    "\n",
    "data_cleaned = data.replace(['NaN', 'NaN '], np.nan)\n",
    "data_cleaned.dropna(inplace=True)\n",
    "\n",
    "cleaned_rows = data_cleaned.shape[0]\n",
    "\n",
    "deleted_rows = original_rows - cleaned_rows\n",
    "print(deleted_rows/original_rows)\n",
    "data = data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e244b-b9e2-4596-8276-a1abac8b1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode 'Road_traffic_density' with label encoding (ordinal)\n",
    "# Define the order of categories\n",
    "categories = ['Low ', 'Medium ', 'High ', 'Jam ']\n",
    "\n",
    "# Convert to ordered categorical and get integer codes\n",
    "data['Rd_traffic_density'] = pd.Categorical(\n",
    "    data['Road_traffic_density'],\n",
    "    categories=categories,\n",
    "    ordered=True\n",
    ").codes\n",
    "\n",
    "# One-Hot Encode the rest (drop_first=True to avoid multicollinearity)\n",
    "one_hot_cols = ['Weatherconditions', 'Type_of_order', 'Type_of_vehicle', 'Festival', 'City']\n",
    "data = pd.get_dummies(data, columns=one_hot_cols, drop_first=True)\n",
    "\n",
    "# Drop the original 'Road_traffic_density' column (optional, now replaced)\n",
    "data.drop(columns='Road_traffic_density', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397ab14-c7b9-408d-94c2-43678e7c3891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns that need to be converted from boolean to 0 and 1\n",
    "boolean_columns = [\n",
    "    'Weatherconditions_Fog', 'Weatherconditions_Sandstorms', 'Weatherconditions_Stormy', \n",
    "    'Weatherconditions_Sunny', 'Weatherconditions_Windy', \n",
    "    'Type_of_order_Drinks ', 'Type_of_order_Meal ', 'Type_of_order_Snack ', \n",
    "    'Type_of_vehicle_electric_scooter ', 'Type_of_vehicle_motorcycle ', 'Type_of_vehicle_scooter ', \n",
    "    'Festival_Yes', 'City_Semi-Urban', 'City_Urban'\n",
    "]\n",
    "\n",
    "# Convert boolean columns to 0 and 1\n",
    "data[boolean_columns] = data[boolean_columns].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5881255-e39b-43c6-875e-73e5e99b255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now define X and y for modeling\n",
    "# Define target and features\n",
    "X = data.drop(columns=[\n",
    "    'Time_taken(min)',        # target\n",
    "    'ID',                     # unique identifier\n",
    "    'Delivery_person_ID',     # personal identifier\n",
    "    'Restaurant_latitude',\n",
    "    'Restaurant_longitude',\n",
    "    'Delivery_location_latitude',\n",
    "    'Delivery_location_longitude',\n",
    "    'Order_Date',\n",
    "    'Time_Orderd',\n",
    "    'Time_Order_picked',\n",
    "])\n",
    "\n",
    "y = data['Time_taken(min)']\n",
    "\n",
    "# Print shapes\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d71b3-a97b-4797-9889-1e28f8b1d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,              \n",
    "    stratify=y,         \n",
    "    random_state=42             \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea60c1-a883-4a73-ae33-65ed5a722205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale numerical columns in X_train\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train[numerical_vars]),\n",
    "    columns=numerical_vars,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# Scale numerical columns in X_test (only transform!)\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test[numerical_vars]),\n",
    "    columns=numerical_vars,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Drop old numerical columns\n",
    "X_train.drop(columns=numerical_vars, inplace=True)\n",
    "X_test.drop(columns=numerical_vars, inplace=True)\n",
    "\n",
    "# Add scaled data back\n",
    "X_train = pd.concat([X_train, X_train_scaled], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_scaled], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba36836-89fc-4029-981a-e20296796b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. k-NN model with grid search and cross-validation\n",
    "knn = KNeighborsRegressor()\n",
    "param_grid = {'n_neighbors': [5, 10, 15, 20, 25]}\n",
    "\n",
    "# 2. Perform Grid Search with 5-fold cross-validation\n",
    "grid_knn = GridSearchCV(knn, param_grid, cv=5)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# 3. Best hyperparameter\n",
    "print(\"Best k (n_neighbors):\", grid_knn.best_params_['n_neighbors'])\n",
    "\n",
    "# 4. Cross-validation mean R² score for best model\n",
    "print(\"Mean CV R^2 Score (best model):\", grid_knn.best_score_)\n",
    "\n",
    "# 5. Evaluate on test set\n",
    "y_pred_knn = grid_knn.predict(X_test)\n",
    "r2_score_knn = r2_score(y_test, y_pred_knn)\n",
    "rmse_knn= mean_squared_error(y_test, y_pred_knn, squared=False)\n",
    "mae_knn= mean_absolute_error(y_test, y_pred_knn)\n",
    "\n",
    "# 6. Compute Adjusted R²\n",
    "n = len(y_test)             # number of samples\n",
    "p = X_test.shape[1]         # number of features\n",
    "adj_r2_knn = 1 - (1 - r2_score_knn) * (n - 1) / (n - p - 1)\n",
    "\n",
    "# 7. Print all metrics\n",
    "print(\"MAE:\", mae_knn)\n",
    "print(\"RMSE:\", rmse_knn)\n",
    "print(\"R^2 Score:\", r2_score_knn)\n",
    "print(\"Adjusted R^2:\", adj_r2_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac3bdef-ef63-4e5f-a9d8-e52bf685130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_knn.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5, edgecolor='k')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Time Taken')\n",
    "plt.ylabel('Predicted Time Taken')\n",
    "plt.title('KNN Regression: Predicted vs Actual')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c0067-7235-4be6-9162-13da67817d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. DecisionTree model\n",
    "\n",
    "opt_tree = DecisionTreeRegressor(random_state=0)\n",
    "dt_params = {'max_depth': range(2, 20)}\n",
    "\n",
    "# Grid search with 5-fold cross-validation\n",
    "grid_tree = GridSearchCV(opt_tree, dt_params, cv=5)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "# (1) Best max_depth chosen\n",
    "print(\"Best max_depth:\", grid_tree.best_params_['max_depth'])\n",
    "\n",
    "# (2) R^2 score on the test set\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "y_pred_tree = grid_tree.predict(X_test)\n",
    "print(\"Test R^2 Score:\", r2_score(y_test, y_pred_tree))\n",
    "\n",
    "# (3) Mean cross-validation R^2 score for the best model\n",
    "print(\"Mean CV R^2 Score (best model):\", grid_tree.best_score_)\n",
    "\n",
    "# Additional evaluation metrics\n",
    "\n",
    "mae_tree = mean_absolute_error(y_test, y_pred_tree)\n",
    "rmse_tree = mean_squared_error(y_test, y_pred_tree, squared=False)\n",
    "\n",
    "# 6. Compute Adjusted R²\n",
    "n = len(y_test)\n",
    "p = X_test.shape[1]\n",
    "adj_r2_tree = 1 - (1 - r2_tree) * (n - 1) / (n - p - 1)\n",
    "\n",
    "# 7. Output results\n",
    "\n",
    "print(\"Adjusted R^2:\", adj_r2_tree)\n",
    "print(\"MAE:\", mae_tree)\n",
    "print(\"RMSE:\", rmse_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30951d-62af-4ceb-a889-52be2a58b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = grid_tree.best_estimator_.feature_importances_\n",
    "plt.barh(X_train.columns, importances)\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1adb14-b79f-46cc-9408-71cfe70dd50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best estimator\n",
    "best_tree = grid_tree.best_estimator_\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(best_tree, \n",
    "          filled=True, \n",
    "          feature_names=X.columns,  \n",
    "          rounded=True, \n",
    "          fontsize=10)\n",
    "best_tree = grid_tree.best_estimator_\n",
    "\n",
    "\n",
    "plt.title(\"Best Decision Tree from GridSearch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55435c8b-e38b-457f-b430-fd7e1a109059",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_tree.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "plt.xlabel(\"Actual Time Taken\")\n",
    "plt.ylabel(\"Predicted Time Taken\")\n",
    "plt.title(\"Prediction vs Actual\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.show()\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_tree,squared=False)\n",
    "print(f\"Test MSE: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe106361-cf54-4dc8-8d99-998c8e2d74f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
