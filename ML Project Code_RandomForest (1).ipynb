{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84ee79-aa69-4c1f-9a52-e36dedbd1d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopy\n",
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87430fb9-ba31-45bf-babf-f78ac0d60060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import os\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647bcdb-9f86-4d4c-b2de-a9618acbc7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c9d19a-9481-4ec4-95f4-efaed35701d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning:\n",
    "\n",
    "# 1.Remove '(min)' from 'Time_taken(min)' and convert it to an integer\n",
    "data['Time_taken(min)'] = data['Time_taken(min)'].str.replace(r'\\(min\\)\\s*', '', regex=True).astype(int)\n",
    "# 2. Remove the 'conditions' prefix from 'Weather conditions'\n",
    "data['Weatherconditions'] = data['Weatherconditions'].str.replace('conditions ', '')\n",
    "\n",
    "# 3. Convert to numeric\n",
    "data['Delivery_person_Age'] = pd.to_numeric(data['Delivery_person_Age'], errors='coerce')  # convert to int, NaNs if invalid\n",
    "data['Delivery_person_Ratings'] = pd.to_numeric(data['Delivery_person_Ratings'], errors='coerce')  # convert to float\n",
    "data['multiple_deliveries'] = pd.to_numeric(data['multiple_deliveries'], errors='coerce')  # convert to int (handle NaNs)\n",
    "\n",
    "# 4. Convert to categorical\n",
    "categorical_columns = [\n",
    "    'Weatherconditions',\n",
    "    'Road_traffic_density',\n",
    "    'Type_of_order',\n",
    "    'Type_of_vehicle',\n",
    "    'Festival',\n",
    "    'City'\n",
    "]\n",
    "data[categorical_columns] = data[categorical_columns].astype('category')\n",
    "\n",
    "# 5. Convert negative latitudes and longitudes to positive for both restaurant and delivery locations\n",
    "data['Restaurant_latitude'] = data['Restaurant_latitude'].abs()\n",
    "data['Restaurant_longitude'] = data['Restaurant_longitude'].abs()\n",
    "data['Delivery_location_latitude'] = data['Delivery_location_latitude'].abs()\n",
    "data['Delivery_location_longitude'] = data['Delivery_location_longitude'].abs()\n",
    "\n",
    "#6. Convert to datetime\n",
    "data['Time_Orderd'] = pd.to_datetime(data['Time_Orderd'], errors='coerce')\n",
    "data['Time_Order_picked'] = pd.to_datetime(data['Time_Order_picked'], errors='coerce')\n",
    "\n",
    "#7. Check for missing values (NaN) in each column of the dataset\n",
    "missing_value = data.isna().sum() + ((data == 'NaN') | (data == 'NaN ')).sum()\n",
    "# Display the number of missing values for each column\n",
    "print(missing_value)\n",
    "# remove the number of blank (missing) values is exactly 3 among the total 12 columns\n",
    "cols_to_check = [\n",
    "    'Delivery_person_Age',\n",
    "    'Delivery_person_Ratings',\n",
    "    'Time_Orderd',\n",
    "    'Weatherconditions',\n",
    "    'Road_traffic_density',\n",
    "    'multiple_deliveries',\n",
    "    'Festival',\n",
    "    'City'\n",
    "]\n",
    "\n",
    "def is_blank(val):\n",
    "    return pd.isna(val) or str(val).strip().lower() == 'nan'\n",
    "rows_with_3_blank = data[cols_to_check].applymap(is_blank).sum(axis=1) == 3\n",
    "data = data[~rows_with_3_blank]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304750d-b142-4878-a369-8c686a34fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Function to calculate distance between restaurant and delivery location (in km)\n",
    "def calculate_distance(row):\n",
    "    restaurant_coords = (row['Restaurant_latitude'], row['Restaurant_longitude'])\n",
    "    delivery_coords = (row['Delivery_location_latitude'], row['Delivery_location_longitude'])\n",
    "    return geodesic(restaurant_coords, delivery_coords).km  # return distance in km\n",
    "data['Delivery_distance_km'] = data.apply(calculate_distance, axis=1)\n",
    "#9. add new column 'Order_to_Pickup_Duration'\n",
    "duration = data['Time_Order_picked'] - data['Time_Orderd']\n",
    "duration = duration.where(duration >= pd.Timedelta(0), duration + pd.Timedelta(days=1))\n",
    "\n",
    "data['Order_to_Pickup_Duration'] = duration.dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c841ffb1-f18b-428d-a16e-188bb4d4a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract restaurant latitude and longitude columns\n",
    "restaurant_data = data[['Restaurant_latitude', 'Restaurant_longitude']]\n",
    "\n",
    "# Step 2: Create map centered on India\n",
    "india_center = [20.5937, 78.9629]\n",
    "map_all_restaurants = folium.Map(location=india_center, zoom_start=5)\n",
    "\n",
    "# Step 3: Plot all restaurant latitudes and longitudes\n",
    "for _, row in restaurant_data.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['Restaurant_latitude'], row['Restaurant_longitude']],\n",
    "        radius=3,\n",
    "        color='blue',  # Blue color for restaurant locations\n",
    "        fill=True,\n",
    "        fill_opacity=0.6\n",
    "    ).add_to(map_all_restaurants)\n",
    "\n",
    "# Step 4: Save the map as an HTML file to view\n",
    "map_all_restaurants\n",
    "#map_all_restaurants.save(\"all_restaurants_map.html\")\n",
    "#print(\"✅ Map saved as 'all_restaurants_map.html'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b635b-d997-46fc-b49a-0b3806fa96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Extract delivery location latitude and longitude columns\n",
    "delivery_data = data[['Delivery_location_latitude', 'Delivery_location_longitude']]    \n",
    "\n",
    "# Step 2: Create map centered on India\n",
    "india_center = [20.5937, 78.9629]\n",
    "map_all_delivery_locations = folium.Map(location=india_center, zoom_start=5)\n",
    "\n",
    "# Step 3: Plot all restaurant latitudes and longitudes\n",
    "for _, row in delivery_data.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['Delivery_location_latitude'], row['Delivery_location_longitude']],\n",
    "        radius=3,\n",
    "        color='red',  # red color for delivery locations\n",
    "        fill=True,\n",
    "        fill_opacity=0.6\n",
    "    ).add_to(map_all_delivery_locations)\n",
    "\n",
    "# Step 4: Save the map as an HTML file to view\n",
    "map_all_delivery_locations\n",
    "#map_all_delivery_locations.save(\"map_all_delivery_locations.html\")\n",
    "#print(\"✅ Map saved as 'map_all_delivery_locations.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260679ed-708e-433d-81f5-af532800b391",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_vars = ['Delivery_person_Age', 'Delivery_person_Ratings', \n",
    "                  'Delivery_distance_km', 'multiple_deliveries','Order_to_Pickup_Duration']\n",
    "\n",
    "categorical_vars = ['Vehicle_condition', 'Weatherconditions', 'Type_of_order',\n",
    "                    'Type_of_vehicle', 'Festival', 'City', 'Road_traffic_density']\n",
    "\n",
    "y = data['Time_taken(min)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12140f2c-5d5b-4bd3-b482-fd3cfdba4bec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "all_vars = numerical_vars + categorical_vars\n",
    "for i, var in enumerate(all_vars):\n",
    "    plt.subplot(4, 3, i+1)\n",
    "    sns.histplot(data[var].dropna(), kde=False, bins=30, color='skyblue')\n",
    "    plt.title(f'Distribution of {var}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829bb2f5-25d6-4495-bd15-3507b700573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#according to the above figure, choose 'Delivery_person_Ratings', 'Festival', and 'City' \n",
    "#missing values with the mode (most frequent value)\n",
    "\n",
    "mode_rating = data['Delivery_person_Ratings'].mode()[0]\n",
    "data['Delivery_person_Ratings'].fillna(mode_rating, inplace=True)\n",
    "\n",
    "data['Festival'] = (\n",
    "    data['Festival'].astype(str).str.strip().replace('NaN', np.nan)\n",
    ")\n",
    "data['Festival'].fillna(data['Festival'].mode()[0], inplace=True)\n",
    "\n",
    "data['City'] = (\n",
    "    data['City'].astype(str).str.strip().replace('NaN', np.nan)\n",
    ")\n",
    "data['City'].fillna(data['City'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff042010-966e-439f-8164-7d27d4a67d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the original records， and remove these missing value records. only 4%\n",
    "\n",
    "original_rows = data.shape[0]\n",
    "\n",
    "data_cleaned = data.replace(['NaN', 'NaN '], np.nan)\n",
    "data_cleaned.dropna(inplace=True)\n",
    "\n",
    "cleaned_rows = data_cleaned.shape[0]\n",
    "\n",
    "deleted_rows = original_rows - cleaned_rows\n",
    "print(deleted_rows/original_rows)\n",
    "data = data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e244b-b9e2-4596-8276-a1abac8b1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode 'Road_traffic_density' with label encoding (ordinal)\n",
    "# Define the order of categories\n",
    "categories = ['Low ', 'Medium ', 'High ', 'Jam ']\n",
    "\n",
    "# Convert to ordered categorical and get integer codes\n",
    "data['Rd_traffic_density'] = pd.Categorical(\n",
    "    data['Road_traffic_density'],\n",
    "    categories=categories,\n",
    "    ordered=True\n",
    ").codes\n",
    "\n",
    "# One-Hot Encode the rest (drop_first=True to avoid multicollinearity)\n",
    "one_hot_cols = ['Weatherconditions', 'Type_of_order', 'Type_of_vehicle', 'Festival', 'City']\n",
    "data = pd.get_dummies(data, columns=one_hot_cols, drop_first=True)\n",
    "\n",
    "# Drop the original 'Road_traffic_density' column (optional, now replaced)\n",
    "data.drop(columns='Road_traffic_density', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397ab14-c7b9-408d-94c2-43678e7c3891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns that need to be converted from boolean to 0 and 1\n",
    "boolean_columns = [\n",
    "    'Weatherconditions_Fog', 'Weatherconditions_Sandstorms', 'Weatherconditions_Stormy', \n",
    "    'Weatherconditions_Sunny', 'Weatherconditions_Windy', \n",
    "    'Type_of_order_Drinks ', 'Type_of_order_Meal ', 'Type_of_order_Snack ', \n",
    "    'Type_of_vehicle_electric_scooter ', 'Type_of_vehicle_motorcycle ', 'Type_of_vehicle_scooter ', \n",
    "    'Festival_Yes', 'City_Semi-Urban', 'City_Urban'\n",
    "]\n",
    "\n",
    "# Convert boolean columns to 0 and 1\n",
    "data[boolean_columns] = data[boolean_columns].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5881255-e39b-43c6-875e-73e5e99b255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now define X and y for modeling\n",
    "# Define target and features\n",
    "X = data.drop(columns=[\n",
    "    'Time_taken(min)',        # target\n",
    "    'ID',                     # unique identifier\n",
    "    'Delivery_person_ID',     # personal identifier\n",
    "    'Restaurant_latitude',\n",
    "    'Restaurant_longitude',\n",
    "    'Delivery_location_latitude',\n",
    "    'Delivery_location_longitude',\n",
    "    'Order_Date',\n",
    "    'Time_Orderd',\n",
    "    'Time_Order_picked',\n",
    "])\n",
    "\n",
    "y = data['Time_taken(min)']\n",
    "\n",
    "# Print shapes\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d71b3-a97b-4797-9889-1e28f8b1d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,              \n",
    "    stratify=y,         \n",
    "    random_state=42             \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea60c1-a883-4a73-ae33-65ed5a722205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale numerical columns in X_train\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train[numerical_vars]),\n",
    "    columns=numerical_vars,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# Scale numerical columns in X_test (only transform!)\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test[numerical_vars]),\n",
    "    columns=numerical_vars,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Drop old numerical columns\n",
    "X_train.drop(columns=numerical_vars, inplace=True)\n",
    "X_test.drop(columns=numerical_vars, inplace=True)\n",
    "\n",
    "# Add scaled data back\n",
    "X_train = pd.concat([X_train, X_train_scaled], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_scaled], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1065f03-c60e-4e37-98ec-92acbe8bc72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ab2354-1bd9-4dd9-be16-0c51c1e00430",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Evaluate model performance\n",
    "rmse_rf = mean_squared_error(y_test, y_pred_rf, squared=False)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_score_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"MAE:\", mae_rf)\n",
    "print(\"RMSE:\", rmse_rf)\n",
    "print(\"R^2 Score:\", r2_score_rf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac3bdef-ef63-4e5f-a9d8-e52bf685130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5, edgecolor='k')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Time Taken')\n",
    "plt.ylabel('Predicted Time Taken')\n",
    "plt.title('Random Forest: Predicted vs Actual')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30951d-62af-4ceb-a889-52be2a58b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the Random Forest model\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(X_train.columns, importances)\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.title(\"Feature Importances from Random Forest\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ef15d-c93b-4052-9888-2670c7a33e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
